{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf8ff43",
   "metadata": {},
   "source": [
    "# Embedding  documento TXT en Chroma de forma persistente\n",
    "\n",
    "https://github.com/hwchase17/chroma-langchain/blob/master/persistent-qa.ipynb\n",
    "\n",
    "Un ejemplo del uso de Chroma DB y LangChain para responder preguntas sobre documentos, \n",
    "con una base de datos persistente localmente. \n",
    "Puede almacenar incrustaciones y documentos y luego utilizarlos nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17475b63-0088-4069-8b6b-5de8fc4a4ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU  langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1aa45b9-c271-4e1a-8609-11022c2de2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU  langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f5e26-b6a8-41f0-81b8-ea32442ae2fa",
   "metadata": {},
   "source": [
    "==========================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89e08cd-cfe6-481a-92a0-0602939635ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12317332-b1ec-4bc9-9325-888bee59c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efbcadd-48c6-4227-a5fe-30a67c05cc68",
   "metadata": {},
   "source": [
    "==========================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4243c24d",
   "metadata": {},
   "source": [
    "## Cargar y procesar documentos\n",
    "\n",
    "Cargue documentos para responder preguntas. Si desea hacer esto sobre sus documentos, esta es la sección que debe reemplazar.\n",
    "\n",
    "A continuación dividimos los documentos en pequeños fragmentos. Esto es para que podamos encontrar los fragmentos más relevantes para una consulta y pasar solo esos al LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb3ad211-bb8c-44d2-a2c4-915bfabaa930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the text\n",
    "loader = TextLoader('./data/DocumentacionMempool.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091c33c",
   "metadata": {},
   "source": [
    "## Inicializar PeristedChromaDB\n",
    "\n",
    "Cree incrustaciones para cada fragmento e insértelas en la base de datos de vectores Chroma. \n",
    "\n",
    "El argumento persist_directory le dice a ChromaDB dónde almacenar la base de datos cuando persiste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b9cbaa4-5063-468a-aeb4-2c0b7847b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "# Al proporcionar un persist_directory se almacenarán las incrustaciones en el disco.\n",
    "persist_directory = './Chroma/db_mempool'\n",
    "\n",
    "embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=embedding, \n",
    "                                 persist_directory=persist_directory\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001341c-c8ec-4c90-8cf7-63ba9029a0f9",
   "metadata": {},
   "source": [
    "==========================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a43e5f",
   "metadata": {},
   "source": [
    "## Conservar la base de datos\n",
    "\n",
    "En un cuaderno, debemos llamar a **persist()** para asegurarnos de que las incrustaciones se escriban en el disco. Esto no es necesario en un script: la base de datos persistirá automáticamente cuando se destruya el objeto del cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7739dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
